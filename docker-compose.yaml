services:
  server:
    build:
      context: .
      dockerfile: server.Dockerfile
      platforms:
        - "linux/amd64"
        - "linux/arm64"
    image: public.ecr.aws/n7b0m3g0/greyhound-guesser/server
    ports:
      - "3000:3000"
  inference:
    build:
      context: .
      dockerfile: inference.Dockerfile
      platforms:
        - "linux/amd64"
        - "linux/arm64"
      args:
        - TORCH_WEIGHT_PATH=${TORCH_WEIGHT_PATH}
    image: public.ecr.aws/n7b0m3g0/greyhound-guesser/inference
    volumes:
      - type: bind
        source: models/
        target: /app/models/
    ports:
      - "5000:5000"
    environment:
      FLASK_DEBUG: true
      TORCH_WEIGHT_PATH: /app/models/gg-2023-11-10_15-17.pt
